batch_size: 1
gradient_penalty_coef: 10
optimizer_params:
    generator:
        cls: "${get_cls: torch.optim.AdamW}"
        n_repeated_updates: 1
        kwargs:
            lr: 3e-4
            betas: [0.0, 0.9]
            weight_decay: 0.0
    critic:
        cls: "${get_cls: torch.optim.AdamW}"
        n_repeated_updates: 5
        kwargs:
            lr: 3e-4
            betas: [0.0, 0.9]
            weight_decay: 0.00
