pretrained: False
batch_size: 1
gradient_penalty_coef: 0.2
optimizer_params:
    generator:
        cls: "${get_cls: torch.optim.AdamW}"
        kwargs:
            lr: 3e-4
            betas: [0.5, 0.9]
            weight_decay: 0.01
    discriminator:
        cls: "${get_cls: torch.optim.AdamW}"
        kwargs:
            lr: 3e-4
            betas: [0.5, 0.9]
            weight_decay: 0.01
